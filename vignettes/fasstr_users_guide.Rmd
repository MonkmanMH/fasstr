---
title: "'fasstr' Users Guide"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r options, include=FALSE}
knitr::opts_chunk$set(eval = nzchar(Sys.getenv("hydat_eval")))
```
The Flow Analysis Summary Statistics Tool for R (`fasstr`) is a set of [R](http://www.r-project.org) functions to tidy, summarize, analyze, trend, and visualize streamflow data. This package summarizes continuous daily mean streamflow data into various daily, monthly, annual, and long-term statistics, completes annual trends and frequency analyses, in both table and plot formats.

This vignette guide contains the following sections to help understand the usage of the `fasstr` functions and arguments:

1. Installation and Loading
2. Flow Data Options
3. Data Cleaning (`add_*` and `fill_*` functions)
4. Data Screening (`screen_*` functions)
5. Summary Statistics (`calc_*` functions)
6. Analyses (`compute_*` functions)
7. Plotting (`plot_*` functions)
7. Writing Tables and Plots (`write_*` functions)
8. Arguments, Options, and Filtering



## 1. Installation and Loading

To install the `fasstr` package, you will first need to install `devtools`, if not already done so, and then `fasstr` using the following code. It may take a few moments as there are several dependecy packages will also be installed, including [tidyhydat](https://cran.r-project.org/web/packages/tidyhydat/index.html) for downloeading Water Survey of Canada hydrometric data, [zyp](https://cran.r-project.org/web/packages/zyp/index.html) for trending, [ggplot2](https://cran.r-project.org/web/packages/ggplot2/index.html) for creating plots, and [dplyr](https://cran.r-project.org/web/packages/dplyr/index.html) and [tidyr](https://cran.r-project.org/web/packages/tidyr/index.html) for various data wrangling and summarizing functions, amongst others. 

```{r, echo=TRUE, eval=FALSE}
install.packages("devtools")
devtools::install_github("bcgov/fasstr")
```
  
To call the `fasstr` functions you can either load the package using the `library()` function or access a specific function using a double-colon (e.g. `fasstr::calc_daily_stats()`). `fasstr` also exports the pipe, ` %>%`, so it can be used for tidy workflows. For this vignette, the `dplyr` package will also be installed.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
library(fasstr)
library(dplyr)
```

To use the `station_number` argument of the `fasstr` functions, you will need to download a HYDAT database to your computer using the following `tidyhydat` function. The function will save the database on your computer and know where to find it each time you open R or RStudio.

```{r, echo=TRUE, eval=FALSE}
tidyhydat::download_hydat()
```
  

## 2. Flow Data Options

All functions in `fasstr` require a daily mean streamflow dataset from one or more hydrometric stations. Long-term and continuous datasets are preferred for most analyses, but seasonal and partial data can be used. Data is provided to each function using either arguments:

- `data`, as a data frame, or
- `station_number`, as a list of Water Survey of Canada HYDAT station numbers.

##### 'data' Arguments

Using the `data` option, a data frame of daily data containing columns of dates (YYYY-MM-DD in date format), values (mean daily discharge in cubic metres per second in numeric format), and, optionally, grouping identifiers (character string of station names or numbers) is called. By default the functions will look for columns identified as 'Date', 'Value', and 'STATION_NUMBER', respectively, to be compatible with the `tidyhydat` defaults, but columns of different names can be identified using the `dates`, `values`, `groups` column arguments (ex.  `values = Yield_mm`). The following is an example of an appropriate dataframe with default column names (STATION_NUMBER not required):

```{r setup, include = FALSE}
data <- tidyhydat::hy_daily_flows("08NM116")
data <- data[,c(1,2,4)]
```

```{r flow_data, warning = FALSE, echo=FALSE}
head(data)
```

The following is an example if your daily data dataframe has the default columns names:

```{r, echo=TRUE, eval=FALSE}
calc_longterm_stats(data = flow_data)
```

The following is an example if your daily data dataframe has the the columns names of "Stations", "Dates", and "Flows":

```{r, echo=TRUE, eval=FALSE}
calc_longterm_stats(data = flow_data,
                    dates = Dates,
                    values = Flows,
                    groups = Stations)
```

The `data` argument is listed first in the list of arguments for each function, so the dataframe can be passed onto other functions using the pipe operator, `%>%`, in a tidy workflow.

##### 'station_number' Argument

Alternatively, you can directly extract flow data directly from a HYDAT database by listing station numbers in the `station_number` argument while leaving the data arguments blank. The following is an example of listing stations:

```{r, echo=TRUE, eval=FALSE}
calc_longterm_stats(station_number = "08NM116")
calc_longterm_stats(station_number = c("08NM116", "08NM242"))
```

After using this argument in your initial function, you do not list it again in subsequent functions but would use the `data` argument. For example:

```{r, echo=TRUE, eval=FALSE}
flow_data <- fill_missing_dates(station_number = "08NM116")
flow_data <- add_date_variables(data = flowdata)
# or
flow_data <- fill_missing_dates(station_number = "08NM116") %>%
  add_date_variables()
```


This package allows for multiple stations (or other groupings) to be analyzed in many of the functions; provided they are identified using the `groups` column argument (defaults to STATION_NUMBER). If grouping column doesn't exist or is improperly named, then all values listed in the `values` column will be summarized.


## 3. Data Cleaning Functions

There are several functions that are used to prepare your flow dataset for your own analysis. These functions start with `add_` or `fill_` and add columns or rows, respectively, to your flow dataframe. These functions include:

- `fill_missing_dates()` - fills in missing dates or dates with no flow values with NA
- `add_date_variables()` - add year, month, and day of year variables (and water years if selected)
- `add_seasons()` - add two and four seasons identifier columns
- `add_rolling_means()` - add rolling n-day averages
- `add_basin_area()` - add a basin area column to daily flows
- `add_daily_volume()` - add daily volumetric flows (in cubic metres)
- `add_daily_yield()` - add daily volumetric runoff yields (in millimetres)
- `add_cumulative_volume()` - add daily cumulative volumetric flows on an annual basis (in cubic metres)
- `add_cumulative_yield()` - add daily cumulative runoff yield flows on an annual basis (in millimetres)


The functions are set up to easily incorporate the use of the pipe operator, like the following:

```{r, warning=FALSE}
fill_missing_dates(station_number = "08NM116") %>% 
  select(Date, Value) %>%  # keeps just the Date and Value columns
  add_date_variables() %>% 
  add_rolling_means(roll_days = 7)
# AND SHOW THE EXAMPLE, EVAL ISNT WORKING
```


##### Filling missing dates

Use fill_missing_dates() to fill any days with missing flow values or missing dates with NA. Missing dates will be filled in gaps between data and completely fill the first and last years (based on selected year type).

Run and compare the following two lines to see how data is filled:

```{r, warning=FALSE, eval=FALSE}
# Very gappy in early years:
tidyhydat::hy_daily_flows(station_number = "08NM116")

# Gaps filled with NA:
fill_missing_dates(station_number = "08NM116")
```

##### Adding date variables and seasons


##### Adding rolling means


##### Adding basin areas


##### Adding daily volumetric or yield flows


##### Adding annual cumualtive daily volumetric or yield flows




## 4. Data screening




### Calculation functions

#### Writing functions



### Plotting functions functions

#### Writing functions



### Compute functions


### Function options


### Calculation functions








### Summary statistics example: long-term statistics

To determine the summary statistics of an entire dataset and by month (mean, median, maximum, minimum, and some percentiles) you can use the `calc_longterm_stats()` function. If the 'Mission Creek near East Kelowna' hydrometric station is of interest you can list the station number in the `HYDAT` argument to obtain the data (if `tidyhydat` and HYDAT are installed). 

```{r example1, warning=FALSE, eval=FALSE}
calc_longterm_stats(station_number = "08NM116")
```

### Plotting example 1: daily summary statistics

To visualize the daily streamflow patterns on an annual basis, the `plot_daily_stats()` function will plot out various summary statistics for each day of the year. Data can also be filtered for certain years of interest (a 1981-2010 normals period for this example) using the `start_year` and `end_year` arguments. Multiple plots are produced with this function, so this example plots just the summary statistics (`[1]`).

```{r plot1, warning=FALSE, eval = FALSE, fig.height = 4, fig.width = 10}
plot_daily_stats(station_number = "08NM116",
                 start_year = 1981,
                 end_year = 2010,
                 log_discharge = TRUE)[1]
```

### Plotting example 2: flow duration curves

Flow duration curves can be produced using the `plot_flow_duration()` function.

```{r plot2, warning=FALSE, eval = FALSE, fig.height = 4, fig.width = 7}
plot_flow_duration(station_number = "08NM116",
                   start_year = 1981,
                   end_year = 2010)
```

### Analysis example: low-flow frequency analysis

This package also provides a function, `compute_frequency_analysis()`, to complete frequency analyses (using the same methods as [HEC-SSP](http://www.hec.usace.army.mil/software/hec-ssp/)). The default fitting distribution is 'log-Pearson Type III', but the 'weibull' distribution can also be used. Other default plotting and fitting methods are described in the function documentation. For this example, the 7-day low-flow (low-flow is default) quantiles are calculated for the Mission Creek hydrometric station using the 'log-Pearson Type III' distribution. With this, several low-flow indicators can be determined (i.e. 7Q5, 7Q10).

```{r example2, eval= FALSE, warning=FALSE}
compute_frequency_analysis(station_number = "08NM116",
                           start_year = 1981,
                           end_year = 2010,
                           rolling_days=7)[5]
```

